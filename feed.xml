<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inference — AI Newsletter</title>
    <link>https://matthewpaver.github.io/ai-weekly/</link>
    <description>The signal in the noise. Curated AI trends, tools, and research — updated every Monday.</description>
    <language>en</language>
    <lastBuildDate>Wed, 11 Feb 2026 09:29:02 +0000</lastBuildDate>
    <atom:link href="https://matthewpaver.github.io/ai-weekly/feed.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title><![CDATA[Testing ads in ChatGPT]]></title>
      <link>https://openai.com/index/testing-ads-in-chatgpt</link>
      <description><![CDATA[OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong privacy protections, and user control.]]></description>
      <category>Industry</category>
      <pubDate>Mon, 09 Feb 2026 11:00:00 +0000</pubDate>
      
    </item>
    <item>
      <title><![CDATA[Introducing SyGra Studio]]></title>
      <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
      <description><![CDATA[Hugging Face shared an update to its open-source AI tooling and model ecosystem.]]></description>
      <category>Tools</category>
      <pubDate>Thu, 05 Feb 2026 16:52:28 +0000</pubDate>
      
    </item>
    <item>
      <title><![CDATA[GitHub Copilot in Visual Studio 2026 – Working Without Agent Skills]]></title>
      <link>https://dev.to/africandeveloper/github-copilot-in-visual-studio-2026-working-without-agent-skills-47m5</link>
      <description><![CDATA[I recently ran an experiment using GitHub Copilot in Visual Studio 2026 to see whether it could generate repetitive code based on a custom coding convention . The goal was simple: Can Copilot adopt a predefined boilerplate template and reuse it across projects?]]></description>
      <category>Tutorials</category>
      <pubDate>Wed, 11 Feb 2026 09:17:46 +0000</pubDate>
      <author>Incomplete Developer</author>
    </item>
    <item>
      <title><![CDATA[Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization]]></title>
      <link>https://arxiv.org/abs/2602.09121</link>
      <description><![CDATA[In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery.]]></description>
      <category>Research</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      <author>Remi Grzeczkowicz, Eric Soriano, Ali Janati et al.</author>
    </item>
    <item>
      <title><![CDATA[Import AI 443: Into the mist: Moltbook, agent ecologies, and the internet in transition]]></title>
      <link>https://importai.substack.com/p/import-ai-443-into-the-mist-moltbook</link>
      <description><![CDATA[Plus, a story about agents corrupting other agents.]]></description>
      <category>Industry</category>
      <pubDate>Mon, 02 Feb 2026 13:31:18 +0000</pubDate>
      <author>Jack Clark</author>
    </item>
    <item>
      <title><![CDATA[LangSmith is Now Available in Google Cloud Marketplace]]></title>
      <link>https://blog.langchain.com/langsmith-is-now-available-in-google-cloud-marketplace/</link>
      <description><![CDATA[Today, we're thrilled to announce that LangSmith, the agent engineering platform from LangChain, is available in Google Cloud Marketplace.]]></description>
      <category>Tools</category>
      <pubDate>Tue, 10 Feb 2026 02:47:44 +0000</pubDate>
      <author>LangChain Accounts</author>
    </item>
    <item>
      <title><![CDATA[Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw & Moltbook]]></title>
      <link>https://lastweekin.ai/p/last-week-in-ai-334-kimi-k25-and</link>
      <description><![CDATA[China’s Moonshot releases a new open source model Kimi K2.5 and a coding agent, Google Brings Genie 3’s Interactive World-Building Prototype to AI Ultra Subscribers, and more!]]></description>
      <category>Industry</category>
      <pubDate>Wed, 04 Feb 2026 05:25:56 +0000</pubDate>
      <author>Last Week in AI</author>
    </item>
    <item>
      <title><![CDATA[Making AI work for everyone, everywhere: our approach to localization]]></title>
      <link>https://openai.com/index/our-approach-to-localization</link>
      <description><![CDATA[OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety.]]></description>
      <category>Industry</category>
      <pubDate>Fri, 06 Feb 2026 10:00:00 +0000</pubDate>
      
    </item>
    <item>
      <title><![CDATA[Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model]]></title>
      <link>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</link>
      <description><![CDATA[Hugging Face shared an update to its open-source AI tooling and model ecosystem.]]></description>
      <category>Tools</category>
      <pubDate>Wed, 04 Feb 2026 15:00:40 +0000</pubDate>
      
    </item>
    <item>
      <title><![CDATA[PABU: Progress-Aware Belief Update for Efficient LLM Agents]]></title>
      <link>https://arxiv.org/abs/2602.09138</link>
      <description><![CDATA[Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost.]]></description>
      <category>Research</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      <author>Haitao Jiang, Lin Ge, Hengrui Cai et al.</author>
    </item>
  </channel>
</rss>